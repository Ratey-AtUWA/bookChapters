---
title: "Counting samples with R"
author: "Andrew Rate"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2: 
    toc_depth: 2
    fig_caption: yes
    number_sections: no
    self_contained: no
  html_document: 
    toc_depth: 2
    fig_caption: yes
    number_sections: no
    self_contained: no
---

## Summary statistics tables which include sample counts above environmental thresholds

Load the R packages we need and set a default table style (&lsquo;`theme`&rsquo;):

```{r preliminaries, message = FALSE, warning = FALSE, include = FALSE}
library(RcmdrMisc)
library(flextable)
  set_flextable_defaults(font.family = "Arial", font.size = 11, 
                       theme_fun = "theme_booktabs", padding = 1)
library(officer)
```

```{r setup, eval=FALSE}
library(RcmdrMisc)
library(flextable)
  set_flextable_defaults(font.family = "Arial", font.size = 11, 
                       theme_fun = "theme_booktabs", padding = 1)
library(officer)
```

## Introduction

In environmental reporting it's common to produce tables containing statistical
summaries of the variables which have been measured at a particular location or
in a specific environment. The statistical parameters presented often include 
basic statistics such as mean, median, standard deviation, minimum, and maximum. 
In many environmental contexts (*e.g*. assessing environments for pollution or 
contamination) it's also very useful to know if any samples have concentrations
of contaminants that exceed environmental thresholds, and if so, how many.

The first code chunk (above) shows that we will use the `RcmdrMisc` package, as 
it contains the useful `numSummary()` function, and the `flextable` package for 
producing nicely-formatted tables. We also load the `officer` package to 
make use of some formatting options in `flextable`. The rest of the code just 
makes use of function in base R.

## Importing environmental threshold data

In this example we will be looking at data on analysis of sediments and soils,
for which environmental guideline values exist in Australia. For sediments we
use the guidelines provided by Water Quality Australia (2024), which were
derived from the interim sediment quality guidelines (ISQG) (hence the name of
the file and data frame!). Soil guideline values are from NEPC (2013).

In the code chunk below we make use of the ability to name rows in R data
frames. This will be useful later on as we can include the row names in indices
to interrogate the data frame for the correct environmental threshold.

```{r}
ISQG <- read.csv("https://github.com/Ratey-AtUWA/bookChapters/raw/main/ISQG.csv")
row.names(ISQG) <- ISQG$Tox
HIL <- read.csv("https://github.com/Ratey-AtUWA/bookChapters/raw/main/HIL_NEPM.csv")
row.names(HIL) <- HIL$Tox
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE, results='hold'}
print(ISQG)
cat("\nNOTES:\nDGV = Default Guideline Value; GV_high = Upper Guideline Value; \n")
cat("Tox = Toxicant\n")
```

```{r echo=FALSE}
colnames(HIL)[3:6] <- 
  c("Resid...A","Resid...B","Recreat...C","Industr...D" )
```


```{r message=FALSE, warning=FALSE, paged.print=FALSE, echo=1, results='hold'}
print(HIL)
cat("\nNOTES:\nTox = Toxicant; Resid = Residential; \n")
cat("Recreat = Recreational / Public Open Space; Industr = Industrial\n")
```

```{r echo=FALSE}
colnames(HIL)[3:6] <- 
  c("Residential_A","Residential_B","Recreational_C","Industrial_D" )
```

We can see from the output above that, for reporting, it would be worthwhile
using a package (such as `flextable`, but there are several others) that can
produce more attractive and readable tables.

## Importing the environmental data we want to summarise

We will use a subset of a dataset generated by some of our environmental science
classes at The University of Western Australia (see Rate and McGrath, 2022 for
an earlier version).

```{r}
git <- "https://github.com/Ratey-AtUWA/bookChapters/raw/main/"
sedsoil <- read.csv(paste0(git,"afs1923abridged.csv"), stringsAsFactors = TRUE)
# convert Year to a factor, and SampID to character
sedsoil$Year <- factor(sedsoil$Year)
sedsoil$SampID <- as.character(sedsoil$SampID)
summary(sedsoil)
```

```{r}
# first define the variables we want to summarise, and make the basic summary
elem0 <- c("As","Cr","Cu","Mn","Ni","Pb","Zn")
(summ0 <- numSummary(sedsoil[,elem0], 
                    statistics = c("mean","sd","quantiles"),
                    quantiles = c(0,0.5,1)))
```

At this stage it's worth inspecting the contents of the list object created 
using `numSummary()`:

```{r}
str(summ0)
```

We can see that the main summary table (`$table`), the count of observations
(`$n`), and the count of missing values (`$NAs`) are stored as separate items in
the list. We will make use of this in the code below; we make a new data frame 
to hold the results, since this is what we need to input into `flextable`.

To perform the actual counting of sample numbers, we use base R's `which()` 
function and the customised column and row names we generated earlier, *e.g*.,
`which(sedsoil[,elem0[i]] > ISQG[elem0[i],"DGV"])`.  

* The code `sedsoil[,elem0[i]]` selects the column from `sedsoil` with the same name as the i^th^ element of the list of variables `elem0`, *i.e*. `elem0[i]`.  
* The code `ISQG[elem0[i],"DGV"]` find the desired value from the ISQG table using the row index `elem0[i]`, and the column index `"DGV"`.  So, the variable names in the data must match the toxicant names in the thresholds table!!
* So, `which(sedsoil[,elem0[i]] > ISQG[elem0[i],"DGV"])` will give the row indices in `sedsoil` for which the condition is `TRUE`, and the code then simply counts these using `length(which(sedsoil[,elem0[i]] > ISQG[elem0[i],"DGV"]))`

```{r paged.print=FALSE}
# just in case our variables have no NA values, make different ways
# of creating the data frame to hold our results

if(length(summ0$NAs)==0){
  OutputDF <- data.frame(summ0$table,n=summ0$n,NAs=rep(0,length(summ0$n)))
} else {
  OutputDF <- data.frame(summ0$table,n=summ0$n,NAs=summ0$NAs)
}

# add blank columns in data frame for environmental thresholds

OutputDF$DGV <- rep(NA,length(elem0))
OutputDF$GV_high <- rep(NA,length(elem0))
OutputDF$HIL_C <- rep(NA,length(elem0))

# count the values for each element exceeding the various thresholds
# and populate the data frame

for(i in 1:length(elem0)){
  OutputDF$DGV[i] <- 
    length(which(sedsoil[,elem0[i]] > ISQG[elem0[i],"DGV"]))
  OutputDF$GV_high[i] <- 
    length(which(sedsoil[,elem0[i]] > ISQG[elem0[i],"GV_high"]))
  OutputDF$HIL_C[i] <- 
    length(which(sedsoil[,elem0[i]] > HIL[elem0[i],"Recreational_C"]))
}

# rename the columns to more understandable names

colnames(OutputDF)[c(3:5,8:10)] <- c("min","median","max","n > DGV","n > GV-high", "n > HIL(C)")
print(OutputDF)
```

We could stop here, but this is not an attractively-formatted table. To make a
publication-quality table, we first make a new data frame with columns and rows
transposed (using `t()`), with the previous column names as the first column.

To avoid lots of nesting of `flextable` functions, we find it easiest to pipe 
the successive lines of code containing formatting modifications. We use the 
[new] native R pipe operator `|>` here, but the older `magrittr` pipe operator 
`%>%` would work if you prefer. Where we need the `officer` package is to 
interpret the formatting option `fp_p=fp_par(text.align = "left", padding.bottom = 6)`
in the `set_caption()` function.

```{r}
# make a new data frame with columns and rows transposed, and the 
# previous column names as the first column:
ft <- as.data.frame(cbind(colnames(OutputDF),t(signif(OutputDF,3))))

# Then, use flextable to output a table in publication-quality form

flextable(ft) |>
  width(j=c(1:7), width=c(3,rep(2.2,6)), unit="cm") |>
  set_header_labels(values=list(V1="")) |>
  align(j=2:8, align="right", part="all") |>
  padding(i=8, padding.top = 8) |>
  bold(bold=TRUE, part="header") |>
  set_caption(caption="Summary statistics for trace element concentrations (mg/kg) in sediment or soil at Ashfield Flats. Abbreviations: n = number of valid observations; NAs = number of missing observations; n > DGV is number of samples exceeding the sediment Default Guideline Value; n > GV-high is number of samples exceeding the sediment upper Guideline Value at which toxicity effects might be expected (Water Quality Australia, 2024). HIL(C) is the human-health based investigation level for Recreational (public open space) land use (NEPC, 2013).", align_with_table=F, fp_p=fp_par(text.align = "left", padding.bottom = 6))
```

<p>&nbsp;</p>

The final table could now go into a report, and most readers would be happy with
its appearance. We could probably do something about the alignment of the
numeric columns, but decimal point alignment is not available in `flextable` yet.

The next really useful type of information to obtain would be **where** the samples
which exceed environmental thresholds are. That question leads us to another
more basic question: &ldquo;*How can we map our data in R*,&rdquo; and so further
chapters will cover preparing maps in R, and from there we can move on to spatial
analysis.

## References

NEPC (National Environment Protection Council). (2013). Schedule B(1): Guideline on the Investigation Levels for Soil and Groundwater. **In** *National Environment Protection (Assessment of Site Contamination) Measure (Amended)*. Commonwealth of Australia. 

Rate, A. W., & McGrath, G. S. (2022). Data for assessment of sediment, soil, and water quality at Ashfield Flats Reserve, Western Australia. *Data in Brief*, **41**, 107970. [https://doi.org/10.1016/j.dib.2022.107970](https://doi.org/10.1016/j.dib.2022.107970){target="_blank"} 


Water Quality Australia. (2024). *Toxicant default guideline values for sediment quality.* Department of Climate Change, Energy, the Environment and Water, Government of Australia. Retrieved 2024-04-11 from [https://www.waterquality.gov.au/anz-guidelines/guideline-values/default/sediment-quality-toxicants](https://www.waterquality.gov.au/anz-guidelines/guideline-values/default/sediment-quality-toxicants){target="_blank"}

<p>&nbsp;</p>
